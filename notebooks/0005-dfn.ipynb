{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from lra import IMDB, default_data_path, LRACIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LRACIFAR10(torch.utils.data.Dataset):\n",
    "#     def __init__(self):\n",
    "#         self.lmax = 32**2\n",
    "#         self.doutput = 10\n",
    "#         self.nvocab = 256\n",
    "    \n",
    "#     def setup(self):\n",
    "\n",
    "#         class Flattener(torch.nn.Module):\n",
    "#             def forward(self, img):\n",
    "#                 return img.flatten().long()\n",
    "\n",
    "#         transform = transforms.Compose([\n",
    "#                 transforms.PILToTensor(),\n",
    "#                 transforms.Grayscale(),\n",
    "#                 Flattener()\n",
    "#             ])\n",
    "\n",
    "#         self.train_dataset = torchvision.datasets.CIFAR10(root=default_data_path,\n",
    "#                                                           download=True,\n",
    "#                                                           transform=transform)\n",
    "#         self.valid_dataset = torchvision.datasets.CIFAR10(root=default_data_path,\n",
    "#                                                           download=True,\n",
    "#                                                           train=False,\n",
    "#                                                           transform=transform)\n",
    "\n",
    "#     def train_dataloader(self, *args, **kwargs):\n",
    "#         return torch.utils.data.DataLoader(self.train_dataset,\n",
    "#                                            *args, **kwargs,\n",
    "#                                            collate_fn=self.collate_fn,\n",
    "#                                            shuffle=True)\n",
    "\n",
    "#     def val_dataloader(self, *args, **kwargs):\n",
    "#         return torch.utils.data.DataLoader(self.valid_dataset,\n",
    "#                                            *args, **kwargs,\n",
    "#                                            collate_fn=self.collate_fn,\n",
    "#                                            shuffle=False)\n",
    "    \n",
    "#     def collate_fn(self, data):\n",
    "#         features, labels = zip(*data)\n",
    "#         features = torch.stack(features, axis=0)\n",
    "#         labels = torch.tensor(labels, dtype=torch.long)\n",
    "#         lengths = features.shape[-1]*torch.ones(features.shape[0], dtype=torch.long)\n",
    "#         return features, labels, {'lengths': lengths}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = LRACIFAR10()\n",
    "dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 39,  32,  28,  ..., 247, 234, 226],\n",
       "         [ 26,  27,  27,  ...,  26,  26,  26],\n",
       "         [254, 248, 154,  ..., 252, 253, 254],\n",
       "         ...,\n",
       "         [ 29,  32,  44,  ..., 155, 155, 157],\n",
       "         [192, 185, 186,  ..., 133, 127, 121],\n",
       "         [151, 149, 150,  ...,  10,  13,  10]]),\n",
       " tensor([6, 3, 5, 8, 5, 9, 4, 8]),\n",
       " {'lengths': tensor([1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024])})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset.train_dataloader(batch_size=8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
